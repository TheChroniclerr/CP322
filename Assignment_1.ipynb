{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheChroniclerr/CP322/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "intro-hw2",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "WOzf3BF6rW5U"
      },
      "source": [
        "# <center><u> CP322: Assignment 1 – Winter 2026 </u> </center>\n",
        "# <center><u>  Due on January 25, 2026 (Before 11:59 PM) </u> </center>\n",
        "\n",
        " This is an individual assignment, and we will practice the concepts to read, clean and explore the dataset, identifying the type of data collected, missing values, anomalies, exploring characteristics of individual variables.\n",
        "\n",
        " For this assignment, you must use Python language syntax. You will use this jupyter notebook to write your code without errors. You will be provided with a Makefile and instructions on using it. If your code does not run, then you will score zero. Therefore, ensure you have removed all syntax errors from your code. •\tGradescope platform would be used to upload the assignments for grading. The link to the Gradescope assignment is available on Myls course page.\n",
        "\n",
        " For submission, Drag and drop your code file(s) into Gradescope. Make sure that your file name should be as suggested in the assignment, using a different name may score zero.\n",
        "\n",
        " - Please note that the submitted code will be checked for plagiarism. By submitting this zip file, you would confirm that you have not received unauthorized assistance in preparing the assignment. You also confirm that you are aware of course policies for submitted work.\n",
        "\n",
        " - Marks will be deducted from any questions where these requirements are not met.\n",
        "\n",
        " - Multiple attempts will be allowed, but only your last submission before the deadline will be graded. Instructor reserves the right to take off points for not following the directions.\n",
        "\n",
        "<b>Warning:</b> Follow the assignment instructions to the letter in terms of the file names and function names, as this assignment will be auto-graded. If anything is not as per the description, the auto-grading fails, and your assignment will be given a Zero mark.\n",
        "\n",
        "Note:\n",
        "- For each question in the assignment, please write down your answer in the answer cell(s) right below the question.\n",
        "- It is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run codes, **NEVER** add cells between a question cell and the answer cell below it. It will cause errors when autograder run.\n",
        "- Finally, unless it is stated otherwise, try to avoid using python for loops or list comprehensions.  The majority of this part of assignment can be done using builtin commands in Pandas and numpy.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL6n15UWrW5V"
      },
      "source": [
        "## Import the Python Packages\n",
        "\n",
        "If any of the package is not available then install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "import",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "thsspvGsrW5W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rng_seed = 42\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "sns.set(style = \"whitegrid\",\n",
        "        color_codes = True,\n",
        "        font_scale = 1.5)\n",
        "plt.style.use('fivethirtyeight')\n",
        "import os # Used to interact with the file system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "download",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "NrZQNoxErW5W"
      },
      "source": [
        "## Part I: Cleaning and Exploring Data with Pandas\n",
        "## 1: Loading Data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6waWvWgIrW5W"
      },
      "source": [
        "### Question 1: Reading in the Files\n",
        "\n",
        "Use the following information and let's attempt to load `bus.csv` dataset, into pandas dataframe named `bus`.\n",
        "\n",
        "URL for loading the business data is:\n",
        "\n",
        "- \"https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/bus.csv\"\n",
        "\n",
        "**Note:** Because of character encoding issue with (`bus`) dataset, it will require an additional argument `encoding='ISO-8859-1'` when calling `pd.read_csv`. At some point in your future, you should read all about [character encodings](https://diveintopython3.problemsolving.io/strings.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HY5nS-YrW5X"
      },
      "outputs": [],
      "source": [
        "bus = pd.read_csv('https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/bus.csv', encoding='ISO-8859-1') # SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TSamlI1yrW5X"
      },
      "source": [
        "Now that you've read in the file, let's try some `pd.DataFrame` methods ([docs](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.html)).\n",
        "Use the `DataFrame.head` method to show the top few lines of the `bus` dataframe. To show multiple return outputs in one single cell, you can use `display(EXPRESSION)`, change the EXPRESSION variable appropriately with code you want to show result/ouput for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "Zps0n3mErW5X"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "ofRfJBhYrW5X"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "business-data",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "2pMYKKNfrW5X"
      },
      "source": [
        "## 2: Examining the Business Data File\n",
        "\n",
        "From its name alone, it is expected that the `bus.csv` file to contain information about the restaurants. Let's investigate the granularity of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpPkKyhCrW5X"
      },
      "outputs": [],
      "source": [
        "bus.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKLjJo69rW5Y"
      },
      "source": [
        "### Question 2a\n",
        "\n",
        "The `bus` dataframe contains a column called `business id column` which probably corresponds to a unique business id (also called `primary key`).  However, let's first rename that column to `bid`.  Modify the `bus` dataframe by renaming that column to `bid`.\n",
        "\n",
        "**Note**: In practice, you might want to do this renaming when the table is loaded but for grading purposes so let's do it here.\n",
        "\n",
        "Hint: Use DATAFRAME.rename(columns={\"OLD_NAME\": \"NEW_NAME\"}). Here, replace CAPITAL LETTERS appropriately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "EstrB6cJrW5Y"
      },
      "outputs": [],
      "source": [
        "bus = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q2a",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "HVwJm6sDrW5Y"
      },
      "source": [
        "### Question 2b\n",
        "\n",
        "Examining the entries in `bus`, is the `bid` unique for each record (i.e. each row of data)? Your code should compute the answer, i.e. don't just hard code `True` or `False`.\n",
        "\n",
        "Hint: use `value_counts()` or `unique()` to determine if the `bid` series has any duplicates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-18T01:21:53.936572Z",
          "start_time": "2018-08-18T01:21:53.927344Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "q2a-answer",
          "locked": false,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "solution",
          "otter_answer_cell"
        ],
        "id": "n9kTkS40rW5Y"
      },
      "outputs": [],
      "source": [
        "is_bid_unique = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwRm4zJ6rW5Y"
      },
      "source": [
        "### Question 2c\n",
        "\n",
        "In the two cells below create two **series**\n",
        "\n",
        "a) where the index is the `name` of the business and the value is the number of records with that `name`\n",
        "b) where the index is the `address` of the business and the value is the number of records with that `address`\n",
        "\n",
        "Order both series in descending order by count. You may need to use `value_counts()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "iKwih84vrW5Y"
      },
      "outputs": [],
      "source": [
        "# Part a)\n",
        "name_counts = ...\n",
        "name_counts.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "r-SgjJSTrW5Y"
      },
      "outputs": [],
      "source": [
        "address_counts = ...\n",
        "address_counts.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "q2b",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "tags": [
          "written"
        ],
        "id": "Nfmfy5Y2rW5Y"
      },
      "source": [
        "### Question 2d\n",
        "\n",
        "Based on the above calculations answer each of the following questions by filling the value in the variable.\n",
        "\n",
        "1. What does each record represent?  \n",
        "1. What is the minimal primary key?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "-kiYj5VJrW5Y"
      },
      "outputs": [],
      "source": [
        "# What does each record represent?  Valid answers are:\n",
        "#    \"One location of a restaurant.\"\n",
        "#    \"A chain of restaurants.\"\n",
        "#    \"A city block.\"\n",
        "q2d_part1 = ...\n",
        "\n",
        "# What is the minimal primary key? Valid answers are:\n",
        "#    \"bid\"\n",
        "#    \"bid, name\"\n",
        "#    \"bid, name, address\"\n",
        "q2d_part2 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "business-data",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "-v6n75Q7rW5Z"
      },
      "source": [
        "## 3: Cleaning the Business Data Postal Codes\n",
        "\n",
        "The business data contains postal code information that can used to aggregate the ratings over regions of the city.  Let's examine and clean the postal code field.  The postal code (sometimes also called a ZIP code) partitions the city into regions:\n",
        "\n",
        "<img src=\"https://usmapguide.com/wp-content/uploads/printable-san-francisco-zip-code-map.jpg\" alt=\"ZIP Code Map\" style=\"width: 600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbukUr3NrW5Z"
      },
      "source": [
        "### Question 3a\n",
        "\n",
        "How many restaurants are in each ZIP code?\n",
        "\n",
        "In the cell below, create a **series** where the index is the postal code and the value is the number of records with that postal code in descending order of count. You may need to use `groupby()`, `size()`, or `value_counts()`. Do you notice any odd/invalid zip codes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d2151d673e6c36a1",
          "locked": false,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "otter_answer_cell"
        ],
        "id": "vmlZMBE1rW5Z"
      },
      "outputs": [],
      "source": [
        "zip_counts = ...\n",
        "print(zip_counts.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJKkQS1crW5Z"
      },
      "source": [
        "### Question 3b\n",
        "\n",
        "Answer the following questions about the `postal_code` column in the `bus` dataframe.\n",
        "\n",
        "1. The ZIP code column is which of the following type of data:\n",
        "    1. Quantitative Continuous\n",
        "    1. Quantitative Discrete\n",
        "    1. Qualitative Ordinal\n",
        "    1. Qualitative Nominal    \n",
        "1. What Python data type is used to represent a ZIP code?\n",
        "\n",
        "*Note*: ZIP codes and postal codes are the same thing.\n",
        "\n",
        "Please write your answers in the variables below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "D4o36m-_rW5Z"
      },
      "outputs": [],
      "source": [
        "# The ZIP code column is which of the following type of data:\n",
        "#   \"Quantitative Continuous\"\n",
        "#   \"Quantitative Discrete\"\n",
        "#   \"Qualitative Ordinal\"\n",
        "#   \"Qualitative Nominal\"\n",
        "q3b_part1 = ...\n",
        "\n",
        "# What Python data type is used to represent a ZIP code?\n",
        "#    \"str\"\n",
        "#    \"int\"\n",
        "#    \"bool\"\n",
        "#    \"float\"\n",
        "q3b_part2 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpa_aZ3trW5Z"
      },
      "source": [
        "### Question 3c\n",
        "\n",
        "In question 3a, a large number of potentially invalid ZIP codes exist (e.g., \"Ca\").  These are likely due to data entry errors.  To get a better understanding of the potential errors in the zip codes, do the following:\n",
        "\n",
        "1. Import a list of valid San Francisco ZIP codes by using `pd.read_json` (from URL = 'https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/sf_zipcodes.json') to load the file `sf_zipcodes.json` and extract a **series** of type `str` containing the valid ZIP codes.  \n",
        "\n",
        "*Hint: set `dtype` when invoking `read_json`.*\n",
        "\n",
        "2. Construct a `DataFrame` containing only the businesses which DO NOT have valid ZIP codes.  You will probably want to use the `Series.isin` function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inQetmjCrW5Z"
      },
      "source": [
        "**Step 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "5MqqtI_4rW5Z"
      },
      "outputs": [],
      "source": [
        "valid_zips = ...\n",
        "valid_zips.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWUpyF4YrW5Z"
      },
      "source": [
        "**Step 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "1rGryN1urW5Z"
      },
      "outputs": [],
      "source": [
        "invalid_zip_bus = ...\n",
        "invalid_zip_bus.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAkbDYDvrW5Z"
      },
      "source": [
        "### Question 3d\n",
        "\n",
        "In the previous question, many of the businesses had a common invalid postal code that was likely used to encode a MISSING postal code.  Do they all share a potentially \"interesting address\"?\n",
        "\n",
        "In the following cell, construct a **series** that counts the number of businesses at each `address` that have this single likely MISSING postal code value.  Order the series in descending order by count.\n",
        "\n",
        "After examining the output.  Answer the following question by filling in the appropriate variable. If we were to drop businesses with MISSING postal code values would a particular class of business be affected?  If you are unsure try to search the web for the most common addresses.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "cTaNc4AkrW5a"
      },
      "outputs": [],
      "source": [
        "missing_zip_address_count = ...\n",
        "missing_zip_address_count.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiLnInHgrW5a"
      },
      "source": [
        "### Question 3e\n",
        "\n",
        "**True or False**:  *If we were to drop businesses with MISSING postal code values, a particular class of business will be affected.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "GkjHwH57rW5a"
      },
      "outputs": [],
      "source": [
        "# True or False:\n",
        "#  If we were to drop businesses with MISSING postal code values\n",
        "#   a particular class of business be affected.\n",
        "q3d_true_or_false = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIbt2vHGrW5a"
      },
      "source": [
        "### Question 3f\n",
        "\n",
        "Examine the `invalid_zip_bus` dataframe we computed above and look at the businesses that DO NOT have the special MISSING ZIP code value.  Some of the invalid postal codes are just the full 9 digit code rather than the first 5 digits.  Create a new column named `postal5` in the original `bus` dataframe which contains only the first 5 digits of the `postal_code` column.   Finally, for any of the `postal5` ZIP code entries that were not a valid San Fransisco ZIP Code (according to `valid_zips`) set the entry to `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "LbWVFk58rW5a"
      },
      "outputs": [],
      "source": [
        "bus['postal5'] = None\n",
        "...\n",
        "\n",
        "# Checking the corrected postal5 column\n",
        "bus.loc[invalid_zip_bus.index, ['bid', 'name', 'postal_code', 'postal5']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNr5KOJsrW5a"
      },
      "source": [
        "## Part II: Linear Regression\n",
        "In this part of the assignment, you will use what you've learned in class to fit a regression model. The ``LinearRegression`` estimator is much more capable to handle multidimensional linear models of the form\n",
        "$$\n",
        "y = a_0 + a_1 x_1 + a_2 x_2 + \\cdots\n",
        "$$\n",
        "where there are multiple $x$ values.\n",
        "Geometrically, this is akin to fitting a plane to points in three dimensions, or fitting a hyper-plane to points in higher dimensions.\n",
        "\n",
        "The multidimensional nature of such regressions makes them more difficult to visualize. We can use the single ``LinearRegression`` estimator to fit lines, planes, or hyperplanes to our data. It still appears that this approach would be limited to strictly linear relationships between variables, but it turns out we can relax this as well.\n",
        "\n",
        "### Loading the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDIECdJPXxOQ"
      },
      "source": [
        "In the English Premier League,  May - July represents a lull period due to the lack of club football. What makes up for it, is the intense transfer speculation that surrounds all major player transfers today. An important part of negotiations is predicting the fair market price for a player. You are tasked with predicting this Market Value of a player using the data provided below\n",
        "\n",
        "The attached data set consists of the following attributes:\n",
        "\n",
        "*  name: Name of the player\n",
        "*  club: Club of the player\n",
        "*  age : Age of the player\n",
        "*  position : The usual position on the pitch\n",
        "*  position_cat: 1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers\n",
        "*  market_value : As on transfermrkt.com on July 20th, 2017\n",
        "*  page_views : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017\n",
        "*  fpl_value : Value in Fantasy Premier League as on July 20th, 2017\n",
        "*  fpl_sel : % of FPL players who have selected that player in their team\n",
        "*  fpl_points : FPL points accumulated over the previous season\n",
        "*  region: 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World\n",
        "*  nationality\n",
        "*  new_foreign : Whether a new signing from a different league, for 2017/18 (till 20th July)\n",
        "*  age_cat\n",
        "*  club_id\n",
        "*  big_club: Whether one of the Top 6 clubs\n",
        "*  new_signing: Whether a new signing for 2017/18 (till 20th July)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGWfXWC_WyJo"
      },
      "outputs": [],
      "source": [
        "football = pd.read_csv('https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/football.csv')\n",
        "football.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wEKYoF4rW5a"
      },
      "source": [
        "### Question 4\n",
        "Drop columns named `'name','fpl_sel','position','nationality','region','new_foreign'` from `football` dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tKabBfbYrW5b"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9MUWrGF5B-N",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "football = ...\n",
        "football.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Qg7kwBzErW5b"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "Let's look at the shape of the updated football data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv2F2YCMrW5b"
      },
      "outputs": [],
      "source": [
        "print('Shape of Data: ', football.shape)\n",
        "print('data.describe:')\n",
        "football.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOpBZhvUrW5b"
      },
      "source": [
        "### Question 5\n",
        "Define the function `correlation` which computes the correlation of dataframe variables and returns the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "FaGjFGIWrW5b"
      },
      "outputs": [],
      "source": [
        "def correlation(dataframe):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja5COgYsrW5b"
      },
      "source": [
        "### Question 6\n",
        "Let's do some visualization to:\n",
        "\n",
        "a) Find the correlation between variables of `football` dataset using `correlation` function defined above, to create a heatmap.\n",
        "\n",
        "b) Create a barplot of `age` vs `market_value`.\n",
        "\n",
        "c) Create a barplot of `position_cat` vs `market_value`.\n",
        "\n",
        "d) Create a barplot of `big_club` vs `market_value`.\n",
        "\n",
        "e) Create a barplot of `club` vs `market_value`.\n",
        "\n",
        "f) Create a scatterplot of `page_views` vs `market_value`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EAzSbsH4rW5b"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWIYBUbp9aH_",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Part a)\n",
        "corr = ...\n",
        "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(240,10,as_cmap=True),\n",
        "            square=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB9RaA03CJ9i",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Part b)\n",
        "...\n",
        "print('Market Value vs Age')\n",
        "print('The age group of 22 to 29 have the most market value.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_CAmYcm_IHV",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Part c)\n",
        "...\n",
        "print('Market Value vs Position Cat')\n",
        "print('The Position Cat 1 has the most market value.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoQB7Iizzfv0",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Part d)\n",
        "...\n",
        "print('Market Value vs Big Club')\n",
        "print('We see that the market value of players from the top 6 clubs is significantly higher than the other players.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLLne2RgF0ke",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Part e)\n",
        "ax = ...\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=80)\n",
        "print('Market Value vs Club')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aIBYnWRLpM-",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Part f)\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5BUj3EKrdl8O"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "### Training Validation Split\n",
        "Now, split the data into train and test datasets. The training data is used to fit the model and test data is used to assess the performance of your model. Note that the seed is set to (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every student. **Do not modify this in the following questions, as our tests depend on this random seed.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuDX8ZnvrW5c"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = train_test_split(football, test_size = 0.25, random_state= 42)\n",
        "display(x_train)\n",
        "display(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq0i8XR4rW5c"
      },
      "source": [
        "Before moving forward, drop the column `club` from `football` dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQQ7c8DorW5d"
      },
      "outputs": [],
      "source": [
        "# Dropping a column from the dataset\n",
        "football = football.drop(columns=['club'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvED9ScqrW5d"
      },
      "outputs": [],
      "source": [
        "response_variable = 'market_value'\n",
        "train_reg, test_reg = train_test_split(football, test_size = 0.25, random_state= 42)\n",
        "X_train_reg = train_reg[train_reg.columns[~train_reg.columns.isin([response_variable])]]\n",
        "y_train_reg = train_reg[[response_variable]]\n",
        "X_test_reg = test_reg[test_reg.columns[~ test_reg.columns.isin([response_variable])]]\n",
        "y_test_reg = test_reg[[response_variable]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA1DM5kerW5d"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "Now that we have matrices, we can build a regression model with `scikit-learn`! Using the [`LinearRegression`] estimator, fit a regression model using `X_train_reg` and `y_train_reg`. Then, output the model's training accuracy below. You should get an training accuracy of around $0.74$ and test accuracy of around $0.80$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXytP0bJIZzR",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "reg_model = ...\n",
        "...\n",
        "\n",
        "training_accuracy = ...\n",
        "test_accuracy = ...\n",
        "\n",
        "print ('Regression: R^2 score on training set', training_accuracy)\n",
        "print ('Regression: R^2 score on test set', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3eWaTXOrW5d"
      },
      "source": [
        "### Question 8\n",
        "\n",
        "Create a dataframe of `y_test_reg` (actual), `predicted values` (predicted), and `residual`. Then create a `lmplot` (actualv vs predicted values)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_ppQ-lNjrW5d"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhSXupNqerdp",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "y_pred = ...\n",
        "y_pred_reshaped = ...\n",
        "residual_df = ...\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bBDDTHgKrW5d"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "### Question 9\n",
        "\n",
        "Also, calculate and print the Root Mean Square Error for the regression model fitted above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "iqWvSSs3rW5d"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "NMRmmkAJrW5e"
      },
      "outputs": [],
      "source": [
        "rmse = ...\n",
        "print(\"Root Mean Square Error: \", rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Bq1luZQirW5e"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## Part 3: Spam/Ham Classification\n",
        "### Feature Engineering, Logistic Regression, Cross Validation\n",
        "In this part of the assignment, you will use what you've learned in class to fit a classifier that can distinguish spam (junk or commercial or bulk) emails from ham (non-spam) emails. In addition to providing some skeleton code to fill in, we will evaluate your work based on your model's accuracy and your written responses in this notebook. This assignment section will cover the following concepts:\n",
        "\n",
        "- Feature engineering with text data\n",
        "- Using `sklearn` libraries to process data and fit classification models\n",
        "- Validating the performance of your model and minimizing overfitting\n",
        "- Generating and analyzing precision-recall curves\n",
        "  \n",
        "**Caution:**\n",
        "This is a **real world** dataset – the emails you are trying to classify are actual spam and legitimate emails. As a result, some of the spam emails may be in poor taste or be considered inappropriate. The benefit of working with realistic data outweighs these innapropriate emails."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "loading",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "KDjSUu5FrW5e"
      },
      "source": [
        "### Loading in the Data\n",
        "\n",
        "In email classification, the goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email.\n",
        "\n",
        "The dataset consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8348 labeled examples, and the unlabeled test set contains 1000 unlabeled examples.\n",
        "\n",
        "Run the following cells to load in the data into Dataframe.\n",
        "\n",
        "The `train` DataFrame contains labeled data that you will use to train your model. It contains four columns:\n",
        "\n",
        "1. `id`: An identifier for the training example\n",
        "1. `subject`: The subject of the email\n",
        "1. `email`: The text of the email\n",
        "1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam)\n",
        "\n",
        "The `test` DataFrame contains 1000 unlabeled emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:42.181245Z",
          "start_time": "2019-04-03T20:17:41.343927Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "fetch-data",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "FjrLilksrW5e"
      },
      "outputs": [],
      "source": [
        "original_training_data = pd.read_csv('https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/spam_data/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/spam_data/test.csv')\n",
        "\n",
        "# Convert the emails to lower case as a first step to processing the text\n",
        "original_training_data['email'] = original_training_data['email'].str.lower()\n",
        "test['email'] = test['email'].str.lower()\n",
        "\n",
        "original_training_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yEZVbLMrW5e"
      },
      "source": [
        "### Question 10a\n",
        "First, let's check if our data contains any missing values. Fill in the cell below to print the number of NaN values in each column. If there are NaN values, replace them with appropriate filler values (i.e., NaN values in the `subject` or `email` columns should be replaced with empty strings). Print the number of NaN values in each column after this modification to verify that there are no NaN values left.\n",
        "\n",
        "Note that while there are no NaN values in the `spam` column, we should be careful when replacing NaN labels. Doing so without consideration may introduce significant bias into our model when fitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:42.203231Z",
          "start_time": "2019-04-03T20:17:42.185104Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b1fb39d9b651ca1b",
          "locked": false,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "otter_answer_cell"
        ],
        "id": "ZxbF3_cRrW5e"
      },
      "outputs": [],
      "source": [
        "print('Before imputation:')\n",
        "print(original_training_data.isnull().sum())\n",
        "# fill in the missing values and update the original_training_data\n",
        "original_training_data = ...\n",
        "print('------------')\n",
        "print('After imputation:')\n",
        "print(original_training_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQDX1JVJrW5e"
      },
      "source": [
        "### Question 10b\n",
        "\n",
        "In the cell below, print the text of the `email` field for the first ham and the first spam email in the original training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:42.247245Z",
          "start_time": "2019-04-03T20:17:42.228451Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "q1-answer",
          "locked": false,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "otter_answer_cell"
        ],
        "id": "sIStoVbPrW5e"
      },
      "outputs": [],
      "source": [
        "first_ham = ...\n",
        "first_spam = ...\n",
        "print(first_ham)\n",
        "print(first_spam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm3IAawprW5e"
      },
      "source": [
        "### Question 10c\n",
        "\n",
        "Discuss one thing you notice that is different between the two emails that might relate to the identification of spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "nHRIBBMUrW5f"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-78513403ef52a957",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "tkaYutJjrW5f"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "### Training Validation Split\n",
        "The training data downloaded is available for both training models and **validating** the models.  Therefore, you must it to separate training and validation datsets.  The **validation data** is used to assess the performance of your classifier once you are finished training. Note that the seed is set to (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every student. **Do not modify this in the following questions, as our tests depend on this random seed.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:42.317970Z",
          "start_time": "2019-04-03T20:17:42.294532Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-873194ed3e686dfb",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "GltQSuBbrW5f"
      },
      "outputs": [],
      "source": [
        "# This creates a 90/10 train-validation split on our labeled data\n",
        "\n",
        "train, val = train_test_split(original_training_data, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "feat-eng",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "FYsKaliIrW5f"
      },
      "source": [
        "### Basic Feature Engineering\n",
        "\n",
        "We would like to take the text of an email and predict whether the email is ham or spam. This is a *classification* problem, so we can use logistic regression to train a classifier. Recall that to train an logistic regression model we need a numeric feature matrix $X$ and a vector of corresponding binary labels $y$.  Unfortunately, our data are text, not numbers. To address this, we can create numeric features derived from the email text and use those features for logistic regression.\n",
        "\n",
        "Each row of $X$ is an email. Each column of $X$ contains one feature for all the emails. We'll guide you through creating a simple feature, and you'll create more interesting ones as you try to increase the accuracy of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM1eMzoDrW5f"
      },
      "source": [
        "### Question 11\n",
        "\n",
        "Create a function called `words_in_texts` that takes in a list of `words` and a pandas Series of email `texts`. It should output a 2-dimensional NumPy array containing one row for each email text. The row should contain either a 0 or a 1 for each word in the list: 0 if the word doesn't appear in the text and 1 if the word does. For example:\n",
        "\n",
        "```\n",
        ">>> words_in_texts(['hello', 'bye', 'world'],\n",
        "                   pd.Series(['hello', 'hello worldhello']))\n",
        "\n",
        "array([[1, 0, 0],\n",
        "       [1, 0, 1]])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:42.337281Z",
          "start_time": "2019-04-03T20:17:42.320567Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "q2-answer",
          "locked": false,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "student",
          "otter_answer_cell"
        ],
        "id": "OiMlAuiYrW5f"
      },
      "outputs": [],
      "source": [
        "def words_in_texts(words, texts):\n",
        "    '''\n",
        "    Args:\n",
        "        words (list): words to find\n",
        "        texts (Series): strings to search in\n",
        "\n",
        "    Returns:\n",
        "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
        "        number of texts and p is the number of words.\n",
        "    '''\n",
        "    indicator_array = ...\n",
        "    return indicator_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "eda",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "MT0J4hitrW5f"
      },
      "source": [
        "We need to identify some features that allow us to distinguish spam emails from ham emails. One idea is to compare the distribution of a single feature in spam emails to the distribution of the same feature in ham emails. If the feature is itself a binary indicator, such as whether a certain word occurs in the text, this amounts to comparing the proportion of spam emails with the word to the proportion of ham emails with the word.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:42.428419Z",
          "start_time": "2019-04-03T20:17:42.386697Z"
        },
        "id": "RiFueWmWrW5g"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "df = pd.DataFrame({\n",
        "    'word_1': [1, 0, 1, 0],\n",
        "    'word_2': [0, 1, 0, 1],\n",
        "    'type': ['spam', 'ham', 'ham', 'ham']\n",
        "})\n",
        "display(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\n",
        "display(df);\n",
        "display(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\n",
        "display(df.melt(\"type\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60xDbjjIrW5g"
      },
      "source": [
        "### Question 12\n",
        "Create a bar chart like the one above comparing the proportion of spam and ham emails containing certain words. Choose a set of words that are different from the ones above, but also have different proportions for the two classes. Please ensure to only consider emails from `train`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "op8UNMRDrW5g"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:43.145246Z",
          "start_time": "2019-04-03T20:17:42.430406Z"
        },
        "nbgrader": {
          "grade": true,
          "grade_id": "q3a-answer",
          "locked": false,
          "points": 2,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "otter_answer_cell"
        ],
        "id": "3_KkD4kUrW5g"
      },
      "outputs": [],
      "source": [
        "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n",
        "some_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\n",
        "Phi_train = ...\n",
        "df = ...\n",
        "df['label'] = train['spam']\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x = \"variable\",\n",
        "            y = \"value\",\n",
        "            hue = \"label\",\n",
        "            data = (df\n",
        "                    .replace({'label':\n",
        "                                {0 : 'Ham',\n",
        "                                 1 : 'Spam'}})\n",
        "                    .melt('label')\n",
        "                    .groupby(['label', 'variable'])\n",
        "                    .mean()\n",
        "                    .reset_index()))\n",
        "\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Proportion of Emails')\n",
        "plt.legend(title = \"\")\n",
        "plt.title(\"Frequency of Words in Spam/Ham Emails\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "grade": false,
          "grade_id": "q3b",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "SmBiCeodrW5g"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "When the feature is binary, it makes sense to compare its proportions across classes (as in the previous question). Otherwise, if the feature can take on numeric values, we can compare the distributions of these values for different classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "classification",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "fSZJXt-MrW5g"
      },
      "source": [
        "## Fit the classification model\n",
        "\n",
        "Notice that the output of `words_in_texts(words, train['email'])` is a numeric matrix containing features for each email. This means we can use it directly to train a classifier!\n",
        "\n",
        "### Question 13\n",
        "\n",
        "You have given you 5 words that might be useful as features to distinguish spam/ham emails. Use these words as well as the `train` DataFrame to create two NumPy arrays: `X_train` and `Y_train`.\n",
        "\n",
        "`X_train` should be a matrix of 0s and 1s created by using your `words_in_texts` function on all the emails in the training set.\n",
        "\n",
        "`Y_train` should be a vector of the correct labels for each email in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:43.726012Z",
          "start_time": "2019-04-03T20:17:43.498088Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "q4-answer",
          "locked": false,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "student",
          "otter_answer_cell"
        ],
        "id": "eNSE2_jFrW5g"
      },
      "outputs": [],
      "source": [
        "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
        "\n",
        "X_train = ...\n",
        "Y_train = ...\n",
        "\n",
        "X_train[:5], Y_train[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mJ0viBKrW5g"
      },
      "source": [
        "### Question 14\n",
        "\n",
        "Now that we have matrices, we can build a model with `scikit-learn`! Using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, train a logistic regression model using `X_train` and `Y_train`. Then, output the model's training accuracy below. You should get an accuracy of around $0.75$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:17:44.593918Z",
          "start_time": "2019-04-03T20:17:43.783872Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "q5-answer",
          "locked": false,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "student",
          "otter_answer_cell"
        ],
        "id": "0-kAjPLLrW5g"
      },
      "outputs": [],
      "source": [
        "model = ...\n",
        "...\n",
        "\n",
        "training_accuracy = ...\n",
        "print(\"Training Accuracy: \", training_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mCDMlz6rW5h"
      },
      "source": [
        "### Evaluating the classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcV6OC7frW5h"
      },
      "source": [
        "The classifier you made above isn't as good as the accuracy would make you believe. First, we are evaluating accuracy on the training set, which may provide a misleading accuracy measure. Accuracy on the training set doesn't always translate to accuracy in the real world (on the test set). In future parts of this analysis, we will hold out some of our data for model validation and comparison.\n",
        "\n",
        "Presumably, our classifier will be used for **filtering**, i.e. preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
        "- False positive (FP): a ham email gets flagged as spam and filtered out of the inbox.\n",
        "- False negative (FN): a spam email gets mislabeled as ham and ends up in the inbox.\n",
        "\n",
        "To be clear, we label spam emails as 1 and ham emails as 0. These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier, in addition to overall accuracy:\n",
        "\n",
        "**Precision** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ of emails flagged as spam that are actually spam.\n",
        "\n",
        "**Recall** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ of spam emails that were correctly flagged as spam.\n",
        "\n",
        "**False-alarm rate** measures the proportion $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$ of ham emails that were incorrectly flagged as spam.\n",
        "\n",
        "The two graphics below may help you understand precision and recall visually:\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"500px\">\n",
        "\n",
        "Note that a true positive (TP) is a spam email that is classified as spam, and a true negative (TN) is a ham email that is classified as ham."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AzTu5KIrW5h"
      },
      "source": [
        "### Question 15a\n",
        "\n",
        "Suppose we have a classifier `zero_predictor` that always predicts 0 (never predicts positive). How many false positives and false negatives would this classifier have if it were evaluated on the training set and its results were compared to `Y_train`? Fill in the variables below (feel free to hard code your answers for this part):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:20:13.853633Z",
          "start_time": "2019-04-03T20:20:13.825724Z"
        },
        "nbgrader": {
          "grade": false,
          "grade_id": "q6a-answer",
          "locked": false,
          "schema_version": 2,
          "solution": true
        },
        "tags": [
          "otter_answer_cell"
        ],
        "id": "SGeNcOPsrW5h"
      },
      "outputs": [],
      "source": [
        "# give your hard coded answers below for the values of False Positives and False Negatives\n",
        "zero_predictor_fp = ...\n",
        "zero_predictor_fn = ...\n",
        "zero_predictor_fp, zero_predictor_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imckiqEirW5h"
      },
      "source": [
        "### Question 15b\n",
        "\n",
        "What is the accuracy and recall of `zero_predictor` (classifies every email as ham) on the training set? Do **NOT** use any `sklearn` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:23:21.553134Z",
          "start_time": "2019-04-03T20:23:21.548219Z"
        },
        "tags": [
          "otter_answer_cell"
        ],
        "id": "E4IOKnOBrW5h"
      },
      "outputs": [],
      "source": [
        "zero_predictor_acc = ...\n",
        "zero_predictor_recall = ...\n",
        "zero_predictor_acc, zero_predictor_recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JkdeDCvrW5h"
      },
      "source": [
        "### Question 15c\n",
        "\n",
        "Compute the precision, recall, and false-alarm rate of the `LogisticRegression` classifier created and trained in Question 14. Do **NOT** use any `sklearn` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-03T20:37:54.875265Z",
          "start_time": "2019-04-03T20:37:54.720667Z"
        },
        "tags": [
          "otter_answer_cell"
        ],
        "id": "HkRDCdpGrW5h"
      },
      "outputs": [],
      "source": [
        "logistic_predictor_precision = ...\n",
        "logistic_predictor_recall = ...\n",
        "logistic_predictor_far = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BmAaRnArW5h"
      },
      "source": [
        "### Question 15d\n",
        "\n",
        "1. How does fitted model's prediction accuracy (number of correct predictions / total) is compared with predicting 0 for every email?\n",
        "2. Given the word features given above, name one reason this classifier is performing poorly. Hint: Think about how prevalent these words are in the email set.\n",
        "3. Which of these two classifiers would you prefer for a spam filter and why? Describe your reasoning and relate it to at least one of the evaluation metrics you have computed so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "csHhPfF4rW5h"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f1dQ-WA5rW5i"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "mlcourse",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "otter": {
      "OK_FORMAT": true,
      "tests": {
        "q1": {
          "name": "q1",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> type(bus) == pd.DataFrame\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q10a": {
          "name": "q10a",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> original_training_data.isnull().sum().sum() == 0\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q10b": {
          "name": "q10b",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> len(first_ham) > 0 and first_ham[:0] == ''\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> len(first_spam) > 0 and first_spam[:0] == ''\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] in first_ham\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] in first_spam\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q11": {
          "name": "q11",
          "points": 3,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> np.allclose(words_in_texts(['hello', 'bye', 'world'], pd.Series(['hello', 'hello worldhello'])), np.array([[1, 0, 0], [1, 0, 1]]))\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> np.allclose(words_in_texts(['a', 'b', 'c', 'd', 'e', 'f', 'g'], pd.Series(['a b c d ef g', 'a', 'b', 'c', 'd e f g', 'h', 'a h'])), np.array([[1, 1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0]]))\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q13": {
          "name": "q13",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> X_train.shape == (7513, 5)\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> np.array_equal(np.unique(X_train), np.array([0, 1]))\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> np.array_equal(np.unique(Y_train), np.array([0, 1]))\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q14": {
          "name": "q14",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> training_accuracy > 0.72\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q15a": {
          "name": "q15a",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> zero_predictor_fp >= 0\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> zero_predictor_fn >= 0\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q15b": {
          "name": "q15b",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> zero_predictor_acc >= 0\nnp.True_",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> zero_predictor_recall >= 0\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q15c": {
          "name": "q15c",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> logistic_predictor_precision >= 0\nnp.True_",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> logistic_predictor_recall >= 0\nnp.True_",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> logistic_predictor_far >= 0\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q2a": {
          "name": "q2a",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> 'bid' in set(bus.columns)\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q2b": {
          "name": "q2b",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> is_bid_unique or ~is_bid_unique\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q2ci": {
          "name": "q2ci",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> len(name_counts) == 5775\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> name_counts[\"Peet's Coffee & Tea\"] == 20\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q2cii": {
          "name": "q2cii",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> len(address_counts) == 5673\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> address_counts['428 11th St'] == 34\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q2d": {
          "name": "q2d",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> q2d_part1 in set(['One location of a restaurant.', 'A chain of restaurants.', 'A city block.'])\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> q2d_part2 in set(['bid', 'bid, name', 'bid, name, address'])\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3a": {
          "name": "q3a",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> type(zip_counts) == pd.Series\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> zip_counts.shape[0] == 63\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> zip_counts['94103'] == 562\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3b": {
          "name": "q3b",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> q3b_part1 in set(['Quantitative Continuous', 'Quantitative Discrete', 'Qualitative Ordinal', 'Qualitative Nominal'])\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> q3b_part2 in set(['str', 'int', 'bool', 'float'])\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3ci": {
          "name": "q3ci",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> valid_zips.dtype == object\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> type(valid_zips) == pd.Series\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3cii": {
          "name": "q3cii",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> type(invalid_zip_bus) == pd.DataFrame\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> len(invalid_zip_bus) == 230\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3d": {
          "name": "q3d",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> type(missing_zip_address_count) == pd.Series\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> len(missing_zip_address_count) == 135\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> missing_zip_address_count['3914 Judah St'] == 1\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3e": {
          "name": "q3e",
          "points": 1,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> type(q3d_true_or_false) == bool\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q3f": {
          "name": "q3f",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> 'postal5' in bus.columns\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> (bus['postal5'].str.len() != 5).sum() == 221\nnp.True_",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> bus['postal5'].isin(valid_zips).sum() == 6032\nnp.True_",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> bus['postal5'].isna().sum() == 221\nnp.True_",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q5": {
          "name": "q5",
          "points": 2,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> data = {'a': [1, 2, 3], 'b': [4, 5, 6]}\n>>> df = pd.DataFrame(data)\n>>> np.isclose(correlation(df), 0.9999999999999999)\narray([[ True,  True],\n       [ True,  True]])",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> data = {'a': [-3, 0, 3], 'b': [-3, 0, 3]}\n>>> df = pd.DataFrame(data)\n>>> np.isclose(correlation(df), 1.0000000000000002)\narray([[ True,  True],\n       [ True,  True]])",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q7": {
          "name": "q7",
          "points": 3,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> training_accuracy > 0.74\nTrue",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> test_accuracy > 0.8\nTrue",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}